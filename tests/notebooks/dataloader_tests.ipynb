{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d94b250-cd4a-44b7-b1df-e389cc94a420",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LynxDataset & dataloader tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dda44f-a2e3-4618-8299-bfd4db6575d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup notebook and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b87119-eb5c-407b-851d-ba8cc480139e",
   "metadata": {},
   "source": [
    "For now, I tested everything in pytorch 2.0.1.\n",
    "\n",
    "I had to install albumentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab73dfe-f60f-443f-9c67-34ca303a5c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Allow reloading of libraries without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e36ef3-0a86-42cc-ba09-92ae1671f936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lynx_id.data.dataset import LynxDataset\n",
    "from pathlib import Path\n",
    "from lynx_id.data.collate import *\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ca50b75-86b2-4269-b65e-11ff73d79d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_csv = Path('/gpfsscratch/rech/ads/commun/datasets/extracted/lynx_dataset_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d338242-b383-4ffe-bfd2-7f0fb6069bc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Single mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b77597fa-d28c-4392-8653-eebb2871b1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataset\n",
    "dataset = LynxDataset(dataset_csv=dataset_csv, loader=\"pil\")\n",
    "\n",
    "input, output = dataset[0]  # Example for getting the first item\n",
    "\n",
    "# Accessing data\n",
    "image = input['image']\n",
    "lynx_id = output['lynx_id']\n",
    "# Access other metadata from input as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8083f535-104d-4500-a7a6-037e8cb2b614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=32, \n",
    "                        shuffle=True, \n",
    "                        num_workers=10,\n",
    "                        prefetch_factor=2, \n",
    "                        persistent_workers=True,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=collate_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "107f46b0-d105-40a6-a954-e42e19cb40e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 49/50 [00:20<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached stop condition after 50 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stop_after = 50 #len(dataloader)\n",
    "# Adjust tqdm's 'total' parameter to stop_after, so the progress bar matches the number of iterations you want.\n",
    "for i, (input, output) in enumerate(tqdm(dataloader, total=stop_after, desc=\"Processing\"), start=1):\n",
    "    if i >= stop_after:\n",
    "        print(\"Reached stop condition after\", i, \"iterations.\")\n",
    "        break  # This will exit the loop once stop_after is reached\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e78738e0-1b80-4a01-acc7-ff9d50cde6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'source', 'pattern', 'date', 'location', 'image_number', 'conf', 'x', 'y', 'width', 'height', 'filepath'])\n",
      "dict_keys(['lynx_id'])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(input.keys())\n",
    "print(output.keys())\n",
    "print(type(input[\"image\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544a98f-0369-4492-8fdd-32ef9d6d06d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Triplet mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5462d938-e5ff-4e2b-849b-79fc5f9b1a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfslocalsup/pub/anaconda-py3/2023.09/envs/pytorch-gpu-2.2.0+py3.11.7/lib/python3.11/site-packages/torchvision-0.17.0+b2383d4-py3.11-linux-x86_64.egg/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/gpfslocalsup/pub/anaconda-py3/2023.09/envs/pytorch-gpu-2.2.0+py3.11.7/lib/python3.11/site-packages/torchvision-0.17.0+b2383d4-py3.11-linux-x86_64.egg/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "weights = torch.load(\"/gpfsscratch/rech/ads/commun/models/resnet50/pretrained_weights.pt\")\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.load_state_dict(weights)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove the last classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40d7e15a-9f2e-4735-9838-26591bb8d0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6360 is out of bounds for dimension 0 with size 4743",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m LynxDataset(dataset_csv\u001b[38;5;241m=\u001b[39mdataset_csv, \n\u001b[1;32m      3\u001b[0m                       loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpil\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                       mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriplet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      9\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#input, output = dataset[0]  # Example for getting the first item\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Accessing data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m (anchor, positive, negative) \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Access other metadata from input as needed\u001b[39;00m\n",
      "File \u001b[0;32m/gpfsdswork/projects/rech/ads/ssos023/DP-SCR_Identify-and-estimate-density-lynx-population/lynx_id/data/dataset.py:347\u001b[0m, in \u001b[0;36mLynxDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_single_item(idx)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriplet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_triplet_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid mode. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriplet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfsdswork/projects/rech/ads/ssos023/DP-SCR_Identify-and-estimate-density-lynx-population/lynx_id/data/dataset.py:262\u001b[0m, in \u001b[0;36mLynxDataset.get_triplet_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_triplet_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    264\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_sampling(idx)\n",
      "File \u001b[0;32m/gpfsdswork/projects/rech/ads/ssos023/DP-SCR_Identify-and-estimate-density-lynx-population/lynx_id/data/dataset.py:294\u001b[0m, in \u001b[0;36mLynxDataset.random_sampling\u001b[0;34m(self, anchor_idx)\u001b[0m\n\u001b[1;32m    292\u001b[0m distances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m-\u001b[39m anchor_embedding, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    293\u001b[0m positive_distance \u001b[38;5;241m=\u001b[39m distances[positive_idx]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 294\u001b[0m negative_distance \u001b[38;5;241m=\u001b[39m \u001b[43mdistances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnegative_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom positive distance for anchor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manchor_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpositive_distance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom negative distance for anchor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manchor_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnegative_distance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6360 is out of bounds for dimension 0 with size 4743"
     ]
    }
   ],
   "source": [
    "# Initialize dataset\n",
    "dataset = LynxDataset(dataset_csv=dataset_csv, \n",
    "                      loader=\"pil\",\n",
    "                      mode='triplet',\n",
    "                      load_triplet_path=\"/gpfsscratch/rech/ads/commun/precompute/triplet_precompute.npz\",\n",
    "                      save_triplet_path=\"/gpfswork/rech/ads/commun/kg_tests/dataloader_tests/triplet_precompute.npz\",\n",
    "                      model=model,\n",
    "                      device=\"auto\", \n",
    "                      verbose=True)\n",
    "#input, output = dataset[0]  # Example for getting the first item\n",
    "# Accessing data\n",
    "for i, (anchor, positive, negative)  enumerate(dataset)\n",
    "# Access other metadata from input as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc4241bd-e968-4647-ada8-f259714c37b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=32, \n",
    "                        shuffle=True, \n",
    "                        num_workers=10,\n",
    "                        prefetch_factor=2, \n",
    "                        persistent_workers=True,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=collate_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5217f04d-d76c-41da-b2f5-8fc2caac09d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 49/50 [00:20<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached stop condition after 50 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stop_after = 50 #len(dataloader)\n",
    "show_data_info = False\n",
    "# Adjust tqdm's 'total' parameter to stop_after, so the progress bar matches the number of iterations you want.\n",
    "for i, (input, output) in enumerate(tqdm(dataloader, total=stop_after, desc=\"Processing\"), start=1):\n",
    "    if show_data_info:\n",
    "        print(input.keys())\n",
    "        print(output.keys())\n",
    "    if i >= stop_after:\n",
    "        print(\"Reached stop condition after\", i, \"iterations.\")\n",
    "        break  # This will exit the loop once stop_after is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1391f98-2916-4990-8c81-9bf15fb12b92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ba3ae-adbe-4b9c-8bfb-ac7f65110b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5272f-4d33-45cb-9416-b28b0aa99bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccbb00-df60-441d-a047-8cd4f1f06cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238f9f0-9e5b-4564-ae30-9c63638bdc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203d742-4df0-42c3-add7-c31d9a097e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def my_collate(batch):\n",
    "    # Initialize lists to gather all elements for each key\n",
    "    images = []\n",
    "    sources = []\n",
    "    patterns = []\n",
    "    dates = []\n",
    "    locations = []\n",
    "    image_numbers = []\n",
    "    lynx_ids = []\n",
    "\n",
    "    # Iterate over each item in the batch\n",
    "    for input_dict, output_dict in batch:\n",
    "        # Append data from input dictionary\n",
    "        images.append(input_dict['image'])  # List of images\n",
    "        sources.append(input_dict['source'])\n",
    "        patterns.append(input_dict['pattern'])\n",
    "        dates.append(input_dict['date'])\n",
    "        locations.append(input_dict['location'])\n",
    "        image_numbers.append(input_dict['image_number'])\n",
    "\n",
    "        # Append data from output dictionary\n",
    "        lynx_ids.append(output_dict['lynx_id'])\n",
    "\n",
    "    # Construct the batched input and output dictionaries\n",
    "    batched_input_dict = {\n",
    "        'images': images,\n",
    "        'sources': sources,\n",
    "        'patterns': patterns,\n",
    "        'dates': dates,\n",
    "        'locations': locations,\n",
    "        'image_numbers': image_numbers\n",
    "    }\n",
    "\n",
    "    batched_output_dict = {\n",
    "        'lynx_ids': lynx_ids\n",
    "    }\n",
    "\n",
    "    return batched_input_dict, batched_output_dict\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=my_collate)\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075e371-515f-4aa6-b9f6-3723c21fb710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(enumerate(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68e3a9-fcd6-43ca-84e6-48aba0d545e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, outputs = batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.2.0_py3.11.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.2.0_py3.11.7"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
